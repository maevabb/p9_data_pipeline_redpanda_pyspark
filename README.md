# ðŸš€ Projet : ModÃ©liser une infrastructure dans le cloud
âœ¨ Auteur : MaÃ«va Beauvillain
ðŸ“… Date de dÃ©but : mars 2025
ðŸ“… DerniÃ¨re MAJ : 31 mars 2025

## Contexte
InduTechData est une entreprise spÃ©cialisÃ©e dans lâ€™analyse de donnÃ©es pour le secteur industriel. Dans le cadre de son projet de modernisation de lâ€™infrastructure et de gestion des donnÃ©es IoT, un POC a Ã©tÃ© mis en place pour la gestion des tickets clients en temps rÃ©el.

Le but de ce projet est de mettre en place un pipeline de donnÃ©es permettant de :

- IngÃ©rer des tickets clients en temps rÃ©el dans un cluster Redpanda.
- Traiter ces tickets Ã  lâ€™aide de PySpark pour en extraire des informations pertinentes et gÃ©nÃ©rer des rapports.

## Objectifs
- **Ingestion des tickets en temps rÃ©el** : Utiliser Redpanda pour ingÃ©rer des tickets clients en temps rÃ©el, contenant des informations sur la demande du client.
- **Traitement des donnÃ©es** : Utiliser PySpark pour analyser ces donnÃ©es, gÃ©nÃ©rer des rapports et extraire des insights.
- **Stockage et visualisation** : Exporter les rÃ©sultats traitÃ©s vers un systÃ¨me de stockage (comme AWS S3) pour la visualisation des rÃ©sultats.

## Architecture
Voici un schÃ©ma de flux des donnÃ©es, montrant les diffÃ©rentes Ã©tapes du pipeline de traitement des tickets clients, depuis la gÃ©nÃ©ration des tickets jusqu'Ã  leur traitement :

```mermaid
flowchart LR
    A[Ticket Producer] -->|Create 100 tickets| B[Redpanda]
    B --> C[Ticket processor]
    C --> D[/Tickets with team added .json /]
    C --> E[/ Group by type request .json/]
    D --> F[Data Storage AWS S3]
    E --> F[Data Storage AWS S3]
```

- **Ticket Producer** : GÃ©nÃ¨re les tickets clients en temps rÃ©el et les envoie dans Redpanda.
- **Redpanda** : Stocke les tickets clients dans un cluster Kafka-compatible pour une gestion en temps rÃ©el.
- **PySpark Processor** : Lit les donnÃ©es de Redpanda, les transforme et les analyse.
- **Data Storage** : Les donnÃ©es traitÃ©es sont stockÃ©es dans un service cloud AWS S3.

## Stack Technique
- **Redpanda** : SystÃ¨me de gestion de flux de donnÃ©es basÃ© sur Kafka, utilisÃ© pour lâ€™ingestion en temps rÃ©el des tickets clients.
- **PySpark** : Framework pour le traitement distribuÃ© de donnÃ©es volumineuses, utilisÃ© pour analyser les tickets.
- **AWS** : Service cloud utilisÃ© pour le stockage des donnÃ©es traitÃ©es (par exemple S3).
- **Docker** : Conteneurisation de lâ€™ensemble des services pour une exÃ©cution simplifiÃ©e.

## PrÃ©requis
Avant de dÃ©marrer le projet, assurez-vous dâ€™avoir les Ã©lÃ©ments suivants installÃ©s sur votre machine :

- Docker et Docker Compose
- AccÃ¨s Ã  un service AWS pour le stockage des rÃ©sultats (S3)

## Installation
1. Clonez le repository :

````bash
git clone https://github.com/votre-utilisateur/p9_data_pipeline_redpanda_pyspark.git
cd p9_data_pipeline_redpanda_pyspark
````

2. Configurez les environnements (infos AWS S3) dans le fichier .env Ã  la racine du projet.

3. Construisez les services Docker :

````bash
docker-compose up -d --build
````

Cette commande dÃ©marrera tous les services nÃ©cessaires Ã  l'exÃ©cution du POC :
- Redpanda pour lâ€™ingestion des tickets.
- Ticket Producer pour gÃ©nÃ©rer des tickets.
- Ticket Processor pour traiter les tickets avec PySpark.
- Redpanda Console pour visualiser les donnÃ©es et interagir avec le cluster Redpanda.

## Utilisation
#### GÃ©nÃ©rer des tickets
Les tickets sont gÃ©nÃ©rÃ©s automatiquement par le service **Ticket Producer**. Ces tickets contiennent des informations gÃ©nÃ©rÃ©es alÃ©atoirement telles que l'ID du client, la demande, la prioritÃ©, et sont envoyÃ©s Ã  Redpanda pour traitement (par dÃ©faut 100 tickets sont gÃ©nÃ©rÃ©s, modifier la variable nb_tickets si besoin).

### Analyser les tickets avec PySpark
Le service **Ticket Processor** utilise PySpark pour lire les tickets depuis Redpanda et effectuer des analyses en temps rÃ©el. Il attibut le ticket Ã  une Ã©quipe selon le type de la demande et effectue une aggrÃ©agation par type de demandes.
 Vous pouvez personnaliser les scripts PySpark pour ajuster les analyses selon vos besoins.

### Visualisation des rÃ©sultats
Les tickets traitÃ©s et les aggrÃ©gations sont stockÃ©s dans S3 en format json pour une analyse future plus approfondie.

### VidÃ©o de dÃ©monstration
Une dÃ©monstration vidÃ©o du pipeline ETL en action est disponible **[ici](https://www.youtube.com/watch?v=9nHeqhERQYE)**. La vidÃ©o couvre :

- La gÃ©nÃ©ration des tickets en temps rÃ©el.
- Leur ingestion dans Redpanda.
- Le traitement des donnÃ©es avec PySpark.
- La visualisation des rÃ©sultats dans S3.

## Conclusion
Ce POC dÃ©montre la faisabilitÃ© de la gestion de tickets clients en temps rÃ©el avec une architecture hybride, utilisant Redpanda pour l'ingestion des donnÃ©es, PySpark pour le traitement des donnÃ©es et AWS pour le stockage des rÃ©sultats.

## Ã€ propos
Ce projet fait partie d'un effort plus large pour moderniser lâ€™infrastructure de gestion des donnÃ©es dâ€™InduTechData en exploitant les services cloud tout en garantissant lâ€™interopÃ©rabilitÃ© avec lâ€™infrastructure existante.

Voici le flux de donnÃ©es du projet global depuis les diffÃ©rentes sources : 

```mermaid
%%{init: {"flowchart": {"htmlLabels": false}} }%%
flowchart LR
    A((Capteurs IoT)) --> B["`**Redpanda** 
    (streaming)`"]
    B --> |"temps rÃ©el"|C["`**AWS S3** 
    (stockage)`"]
    C:::cloudclass --> |"`temps rÃ©el
    (kinesis)`"|D["`**AWS Redshift** 
    (analyse)`"]:::cloudclass
    E{{"`**SQL Server**
    (ERP & CRM)`"}}:::otherclass --> |"`sync via
    AWS DMS`"|D
    F{{"`fa:fa-lock
    Active 
    Directory`"}}:::otherclass --> |"sync"|G["`fa:fa-lock
    AWS
    Managed AD`"]:::cloudclass
    classDef cloudclass fill:#FDF1B8
    classDef cloudclass stroke:#000000
    classDef otherclass fill:#F0FFFF
    classDef otherclass stroke:#000000
```