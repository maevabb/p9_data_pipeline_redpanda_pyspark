# üöÄ Projet : Mod√©liser une infrastructure dans le cloud
‚ú® Auteur : Ma√´va Beauvillain
üìÖ Date de d√©but : mars 2025
üìÖ Derni√®re MAJ : 31 mars 2025

## Contexte
InduTechData est une entreprise sp√©cialis√©e dans l‚Äôanalyse de donn√©es pour le secteur industriel. Dans le cadre de son projet de modernisation de l‚Äôinfrastructure et de gestion des donn√©es IoT, un POC a √©t√© mis en place pour la gestion des tickets clients en temps r√©el.

Le but de ce projet est de mettre en place un pipeline de donn√©es permettant de :

- Ing√©rer des tickets clients en temps r√©el dans un cluster Redpanda.
- Traiter ces tickets √† l‚Äôaide de PySpark pour en extraire des informations pertinentes et g√©n√©rer des rapports.

## Objectifs
- **Ingestion des tickets en temps r√©el** : Utiliser Redpanda pour ing√©rer des tickets clients en temps r√©el, contenant des informations sur la demande du client.
- **Traitement des donn√©es** : Utiliser PySpark pour analyser ces donn√©es, g√©n√©rer des rapports et extraire des insights.
- **Stockage et visualisation** : Exporter les r√©sultats trait√©s vers un syst√®me de stockage (comme AWS S3) pour la visualisation des r√©sultats.

## Architecture
Voici un sch√©ma de flux des donn√©es, montrant les diff√©rentes √©tapes du pipeline de traitement des tickets clients, depuis la g√©n√©ration des tickets jusqu'√† leur traitement :

```` mermaid
graph TD
  A[Ticket Producer] --> B[Redpanda]
  B --> C[PySpark Processor]
  C --> D[Data Storage (S3)]
````

- **Ticket Producer** : G√©n√®re les tickets clients en temps r√©el et les envoie dans Redpanda.
- **Redpanda** : Stocke les tickets clients dans un cluster Kafka-compatible pour une gestion en temps r√©el.
- **PySpark Processor** : Lit les donn√©es de Redpanda, les transforme et les analyse.
- **Data Storage** : Les donn√©es trait√©es sont stock√©es dans un service cloud AWS S3.

## Stack Technique
- **Redpanda** : Syst√®me de gestion de flux de donn√©es bas√© sur Kafka, utilis√© pour l‚Äôingestion en temps r√©el des tickets clients.
- **PySpark** : Framework pour le traitement distribu√© de donn√©es volumineuses, utilis√© pour analyser les tickets.
- **AWS** : Service cloud utilis√© pour le stockage des donn√©es trait√©es (par exemple S3).
- **Docker** : Conteneurisation de l‚Äôensemble des services pour une ex√©cution simplifi√©e.

## Pr√©requis
Avant de d√©marrer le projet, assurez-vous d‚Äôavoir les √©l√©ments suivants install√©s sur votre machine :

- Docker et Docker Compose
- Acc√®s √† un service AWS pour le stockage des r√©sultats (S3)

## Installation
1. Clonez le repository :

````bash
git clone https://github.com/votre-utilisateur/p9_data_pipeline_redpanda_pyspark.git
cd p9_data_pipeline_redpanda_pyspark
````

2. Configurez les environnements (infos AWS S3) dans le fichier .env √† la racine du projet.

3. Construisez les services Docker :

````bash
Copier
docker-compose up --build
````

Cette commande d√©marrera tous les services n√©cessaires √† l'ex√©cution du POC :
- Redpanda pour l‚Äôingestion des tickets.
- Ticket Producer pour g√©n√©rer des tickets.
- Ticket Processor pour traiter les tickets avec PySpark.
- Redpanda Console pour visualiser les donn√©es et interagir avec le cluster Redpanda.

## Utilisation
#### G√©n√©rer des tickets
Les tickets sont g√©n√©r√©s automatiquement par le service **Ticket Producer**. Ces tickets contiennent des informations g√©n√©r√©es al√©atoirement telles que l'ID du client, la demande, la priorit√©, et sont envoy√©s √† Redpanda pour traitement (par d√©faut 100 tickets sont g√©n√©r√©s, modifier la variable nb_tickets si besoin).

### Analyser les tickets avec PySpark
Le service **Ticket Processor** utilise PySpark pour lire les tickets depuis Redpanda et effectuer des analyses en temps r√©el. Il attibut le ticket √† une √©quipe selon le type de la demande et effectue une aggr√©agation par type de demandes.
 Vous pouvez personnaliser les scripts PySpark pour ajuster les analyses selon vos besoins.

### Visualisation des r√©sultats
Les tickets trait√©s et les aggr√©gations sont stock√©s dans S3 en format json  pour une analyse plus approfondie.

### Vid√©o de d√©monstration
Une d√©monstration vid√©o du pipeline ETL en action est disponible **ici**. La vid√©o couvre :

- La g√©n√©ration des tickets en temps r√©el.
- Leur ingestion dans Redpanda.
- Le traitement des donn√©es avec PySpark.
- La visualisation des r√©sultats dans S3.

## Conclusion
Ce POC d√©montre la faisabilit√© de la gestion de tickets clients en temps r√©el avec une architecture hybride, utilisant Redpanda pour l'ingestion des donn√©es, PySpark pour le traitement des donn√©es et AWS pour le stockage des r√©sultats.

## √Ä propos
Ce projet fait partie d'un effort plus large pour moderniser l‚Äôinfrastructure de gestion des donn√©es d‚ÄôInduTechData en exploitant les services cloud tout en garantissant l‚Äôinterop√©rabilit√© avec l‚Äôinfrastructure existante.